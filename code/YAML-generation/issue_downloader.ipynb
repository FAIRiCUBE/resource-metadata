{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da12c57f",
   "metadata": {},
   "source": [
    "# ISSUE DOWNLOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6b6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c3c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_resource(url, auth):\n",
    "    \"\"\"\n",
    "    Downloads JSON from an API URL. Github paginates when many items are\n",
    "    present; if a requested URL has multiple pages, this function will request\n",
    "    all the pages and concatenate the results.\n",
    "    \"\"\"\n",
    "    print(url)\n",
    "    r = requests.get(url, auth=auth)\n",
    "    if not r.ok:\n",
    "        raise Exception('Github returned status code {} ({}) when loading {} . Check that '\n",
    "                        'your username, password, and repo name are correct.'.format(r.status_code, r.reason, url))\n",
    "    data = r.json()\n",
    "    # Load data from the next pages, if any\n",
    "    if 'link' in r.headers:\n",
    "        pages = {rel: url for url, rel in re.findall(r'<(.*?)>;\\s+rel=\\\"(.*?)\\\"', r.headers['link'])}\n",
    "        print(pages)\n",
    "        if 'next' in pages:\n",
    "            data.extend(load_all_resource(pages['next'], auth))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_json(username, password, repo):\n",
    "    \"\"\"\n",
    "    Downloads all of the JSON for all of the issues in a repository. Also\n",
    "    retrieves the comments and events for each issue, and saves those in the\n",
    "    'comments' and 'events' attributes in the dictionary for each issue.\n",
    "    \"\"\"\n",
    "    data = load_all_resource('https://api.github.com/repos/{}/issues?state=all'.format(repo),\n",
    "                       auth=(username, password))\n",
    "    # Load the comments and events on each issue\n",
    "    for issue in data:\n",
    "        print('#{}'.format(issue['number']))\n",
    "        issue['comments'] = load_all_resource(issue['comments_url'],\n",
    "                                              auth=(username, password))\n",
    "        issue['events'] = load_all_resource(issue['events_url'],\n",
    "                                            auth=(username, password))\n",
    "    return data\n",
    "\n",
    "\n",
    "def download_embedded_images(json_data, folder):\n",
    "    \"\"\"\n",
    "    Downloads all of the images attached to issues for the repository.\n",
    "    \"\"\"\n",
    "    json_str = json.dumps(json_data)\n",
    "    for path in re.findall(r'[\\(\"]https:\\/\\/cloud.githubusercontent.com\\/(.*?)[\\)\"]', json_str):\n",
    "        img_url = 'https://cloud.githubusercontent.com/'+path\n",
    "        response = requests.get(img_url, stream=True)\n",
    "        if not response.ok:\n",
    "            raise Exception('Got a bad response while download the embedded image from {}! {} {}'.format(img_url, response.status_code, response.reason))\n",
    "        with open(os.path.join(folder, base64.b64encode(path)+'.'+path.rsplit('.',1)[-1]), 'wb') as f:\n",
    "            for block in response.iter_content(1024):\n",
    "                if not block:\n",
    "                    break\n",
    "                f.write(block)\n",
    "\n",
    "                \n",
    "def mkdown_p(text):\n",
    "    \"\"\"\n",
    "    Generates the markdown syntax for a paragraph.\n",
    "    \"\"\"\n",
    "    return text + '\\n'\n",
    "\n",
    "\n",
    "def build_markdown(repo, data, issue_number):\n",
    "    \"\"\"\n",
    "    Generates the markdown for a repository's issue page. The resulting markdown\n",
    "    is a crude-but-functional mimicry of Github's issues.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    i = 1\n",
    "    for issue in sorted(data, key=lambda x: x['number']):\n",
    "        if i == issue_number:\n",
    "            lines.append(mkdown_p(issue['body']))\n",
    "        i = i+1\n",
    "    return ''.join(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b00609d7",
   "metadata": {},
   "source": [
    "### Issue downloading and saving in JSON/markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f800cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issue(user, passw, repository, issue_number, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "           os.makedirs(output_folder)\n",
    "\n",
    "    print('\\033[32m' + 'Downloading issues...' + '\\033[0m')\n",
    "    issues = get_json(user, passw, repository)\n",
    "\n",
    "    print('\\033[32m' + 'Downloading images attached to issues...' + '\\033[0m')\n",
    "    download_embedded_images(issues, output_folder)\n",
    "\n",
    "    print('\\033[32m' + 'Saving JSON...' + '\\033[0m')\n",
    "    with codecs.open(os.path.join(output_folder, 'issues.json'), 'w', 'utf-8') as f:\n",
    "        json.dump(issues, f, indent=4)\n",
    "\n",
    "    print('\\033[32m' + 'Saving Markdown...' + '\\033[0m')\n",
    "    markdown = build_markdown(repository, issues, issue_number)\n",
    "    with codecs.open(os.path.join(output_folder, 'issue.txt'), 'w', 'utf-8') as f:\n",
    "        f.write(markdown)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
